<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI in a Box</title>
  <style>
    body {
      font-family: Helvetica, Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #ffffff;
      color: #333;
      line-height: 1.6;
    }

    /* HEADER */
    header {
      background-color: #f8f9fa;
      padding: 40px 20px;
      text-align: center;
      border-bottom: 1px solid #ddd;
      position: relative;
    }
    .logo-container {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 1rem;
      margin-bottom: 10px;
    }
    /* Logo - uses aiab.png from same directory */
    .site-logo {
      max-height: 60px;
    }
    /* Fallback text if logo fails to load */
    .site-title {
      font-size: 2em;
      margin: 0;
      display: none; 
    }
    header p {
      margin: 0;
      color: #555;
      font-size: 1.2em;
    }

    /* MAIN CONTAINER for the BOXED sections only (below the heroes) */
    main {
      max-width: 900px;
      margin: 40px auto;
      padding: 0 20px;
    }

    /* =========================
       HERO SECTION 1: “What We Do”
       ========================= */
    .hero-section {
      width: 100%;
      padding: 60px 0;
      margin-bottom: 40px;
      /*background: #f8f8f8 url('soon.png') center/cover no-repeat;
      /* We remove any box/border from the first hero. */
      /*background: #f8f8f8 center/cover no-repeat;*/
      position: relative;
      font-weight: lighter;
    }
    .hero-content {
      max-width: 900px;
      margin: 0 auto;
      padding: 0 20px;
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
    }
    .hero-left-column,
    .hero-right-column {
      flex: 1 1 300px;
    }
    .hero-left-column img {
      max-width: 200px;
      width: 100%;
      border-radius: 4px;
      margin-bottom: 15px;
    }
    .hero-right-column p {
      margin-bottom: 20px;
      text-align: justify;
    }

    /* =========================
       HERO SECTION 2: “Our Clients”
         with repeating border & sunken effect
       ========================= */
    .clients-hero {
      /* same base hero styling */
      width: 100%;
      padding: 60px 0;
      margin-bottom: 40px;
      /*background: #f8f8f8;*/
      background: linear-gradient(to right, #ffce97, #faabfc, #9cd2fe);
      position: relative;
      /* “Sunken” effect (inset shadow) */
      box-shadow: inset 0 0 15px rgba(0,0,0,0.5);
      overflow: hidden;
    }
    .clients-hero .hero-content {
      max-width: 900px;
      margin: 0 auto;
      padding: 0 20px;
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
    }
    /* Repeating “soon.png” as border top & bottom via pseudo-elements */
    .clients-hero::before,
    .clients-hero::after {
      content: '';
      display: block;
      position: absolute;
      left: 0;
      width: 100%;
      height: 30px;
      /*background: url('soon.png') repeat-x center/auto;*/
      z-index: 2;
    }
    .clients-hero::before {
      top: 0;
    }
    .clients-hero::after {
      bottom: 0;
    }
    /* Column images in the second hero also use soon.png if needed */
    .clients-hero .hero-left-column img {
      max-width: 200px;
      width: 100%;
      border-radius: 4px;
      margin-bottom: 15px;
    }
    .clients-hero .hero-right-column p {
      margin-bottom: 20px;
      text-align: justify;
    }

    /* ==================================
       BOXED SECTIONS (remaining content)
       ================================== */
    section.boxed-section {
      background-color: #fafafa;
      padding: 30px;
      border-radius: 8px;
      margin-bottom: 40px;
      border: 1px solid #e8e8e8;
      transition: box-shadow 0.3s ease, transform 0.3s ease;
      /*position: relative; /* for bottom alignment of the image */
    }
    section.boxed-section:hover {
      box-shadow: 0 8px 20px rgba(0, 0, 0, 0.05);
      transform: translateY(-2px);
    }
    .section-content {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
    }
    .left-column {
      flex: 1 1 300px;
      max-width: 40%;
      /* 
         Align image at bottom using flex. 
         The heading & subtitle go at the top by default,
         the image is pushed to the bottom.
      */
/*      display: flex;
      flex-direction: column;
      justify-content: flex-end;
      align-items: flex-start; */
    }
    .right-column {
      flex: 1 1 400px;
      max-width: 60%;
    }

    /* HEADINGS & SUBTITLES (Boxed Sections) */
    section.boxed-section h2 {
      font-size: 1.6em;
      margin-bottom: 8px;
      /* 4-color gradient text effect */
      background: linear-gradient(to right, #FF7A18, #AF002D, #319197, #8F00FF);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      text-fill-color: transparent;
      /* Ensure the heading is at the top (before the image) */
      align-self: flex-start;
    }
    .subtitle {
      font-size: 1em;
      color: #666;
      margin: 0 0 15px 0;
      /* Also ensure it’s above the image */
      align-self: flex-start;
    }

    /* IMAGES in boxed sections (fade-in, bottom aligned, max-height 30px) */
    .left-column img {
      max-height: 30px;
      /* fade-in initial state */
      opacity: 0; 
      transition: opacity 1s ease-in-out;
      /* align self at bottom */
      align-self: flex-end;
    }
    .reveal {
      opacity: 1 !important;
    }

    /* PARAGRAPH STYLES (Boxed) */
    .right-column p {
      margin-bottom: 20px;
      text-align: justify;
    }

    /* FOOTER */
    footer {
      text-align: center;
      padding: 20px;
      background-color: #f8f9fa;
      border-top: 1px solid #ddd;
      color: #555;
    }
    footer a {
      color: #555;
      text-decoration: none;
      font-weight: bold;
    }
    footer a:hover {
      text-decoration: underline;
    }

    /* RESPONSIVE TWEAKS */
    @media (max-width: 768px) {
      .hero-left-column,
      .hero-right-column,
      .left-column,
      .right-column {
        max-width: 100%;
      }
    }

  </style>
</head>
<body onload="fadeInImages()">

  <!-- HEADER -->
  <header>
    <div class="logo-container">
      <!-- Logo now points to aiab.png in the same directory -->
      <img 
        class="site-logo" 
        src="aiab.png" 
        alt="AI in a Box Logo" 
        onerror="this.style.display='none';document.querySelector('.site-title').style.display='block';"
      />
      <h1 class="site-title">AI in a Box</h1>
    </div>
    <p>Accelerators to Launch AI Products Faster</p>
  </header>

  <!-- =========================
       HERO SECTION 1: “What We Do”
       Titles removed
       ========================= -->
  <section class="hero-section">
    <div class="hero-content">
      <p>
        AI in a Box is a series of packaged AI use cases which can serve to accelerate product
        launches involving Artificial Intelligence or Machine Learning significantly. We use our
        decades of experience in the industry to clearly identify various kinds of risks in the AI
        development life cycle and pre-empt them with simple and focused solutions which solve specific 
        problems way faster. 
        We stand on the shoulders of giants by building upon the open source AI and ML algorithms and ideas 
        and translate generic libraries into task-specific solutions in the most optimal way.
      </p>
      <p>
        Our unique selling point is speed. From ideation to deployment, we compress the AI 
        product lifecycle so you can validate ideas and capture value in record time. Whether 
        you are a startup or an established enterprise, our proprietary accelerators, 
        methodologies, and tooling ensure you stay ahead of the curve in a competitive AI landscape.
      </p>
    </div>
  </section>

  <!-- =========================
       HERO SECTION 2: “Our Clients”
       Titles removed, repeating border top & bottom
       ========================= -->
  <section class="hero-section clients-hero">
    <div class="hero-content">
      <div class="left-column">
        <h2>Our Clients</h2>
      </div>
      <div class="right-column">
        <img 
        src="instore.png"
        alt="Our Clients Illustration"
        width="150px"
        />
        <img 
          src="elecon.png"
          alt="Our Clients Illustration"
          width="150px"
        />
        <img 
          src="flash.png"
          alt="Our Clients Illustration"
          width="150px"
        />
        <img 
        src="radicon.png"
        alt="Our Clients Illustration"
        width="150px"
        />
        <img 
          src="eimco.png"
          alt="Our Clients Illustration"
          width="150px"
        />
      </div>      
    </div>
  </section>

  <!-- ==================================
       BOXED SECTIONS (remaining content)
       ================================== -->

  <h1 style="text-align:center">Our Products</h1>
  <main>
    <!-- Brand Registry -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>Longlegs</h2>
          <p class="subtitle">Focused Brand Information Crawler guided by LLMs on Traditional Search Engines</p>
          <!-- Placeholder image changed to soon.png -->
          <img src="rtl.png" alt="Brand Registry Illustration"/>
        </div>
        <div class="right-column">
          <p>
            We crawl the Web for brands and extract relevant information to understand various facets of a 
            brand. We can also quickly gather details about thousands of brands in different verticals based
            on our clients' business needs. We use a proprietary crawler seeded with initial brands either
            provided by the client or from a well-known knowledge base like DBPedia. We use a combination 
            of LLM guided crawls and searches to quickly extract troves of specific information to create
            brand data.
          </p>
          <p>
            For instance, a luxury brand purchase (like Louis Vuitton) provides insights into 
            a user's affluence, while shopping at stores like Costco or Walmart highlights a 
            different facet of consumer behavior and a brand like Titleist or Gibson sheds light on 
            entirely new segments. With this brand registry, you can better understand your customers 
            and craft solutions tailored to their brand affinities.
          </p>
        </div>
      </div>
    </section>

    <!-- Semantic Search -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>OmniSearch</h2>
          <p class="subtitle">Multi-modal Semantic Search integrating Images, Audio, Keywords and Semantics</p>
          <img src="rtl.png" alt="Semantic Search Illustration"/>
        </div>
        <div class="right-column">
          <p>
            Modern search is no longer just about text, it also encompasses audio, video and images. 
            Search is not about finding mere keywords—it's about identifying the 
            true intent of a query and finding relevant content whether or not we have the text. 
            Our novel combination of traditional search and latent vector 
            embedding of content and queries ensures that if someone searches for “Black Nike basketball shoes with 
            red highlight,” the system prioritizes “Nike” while finding the best attribute matches 
            for the rest in the images, description and reviews.
          </p>
          <p>
            We pioneered a new ranking methodology based on our original research and combine different 
            indices and allow our clients to tune search relevance accordingly. We use a combination of Solr,
            Vector Databases and Embedding models to achieve our results. We have shown significant uplift when 
            compared to commercial-grade product search engines employed by large e-commerce players.

          </p>
        </div>
      </div>
    </section>

    <!-- Local LLM Serving -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>Liminal</h2>
          <p class="subtitle">Task Oriented local LLM serving</p>
          <img src="soon.png" alt="Local LLM Serving Illustration"/>
        </div>
        <div class="right-column">
          <p>
            Generic LLMs excel at conversational tasks, but they aren't always optimal for highly 
            specific tasks with strict output requirements. We built a specialized library that 
            runs on local LLM instances and enforces precise outputs suitable for machine consumption.
            We make it stupidly simple to programmatically configure new tasks and set up LLM inference 
            endpoints.
          </p>
          <p>
            On top of LLM serving we enable features like Pydantic output, with task specific caching.
            These advances recently introduced by commercial LLMs have been part of our proprietary 
            library from the start, enabling seamless integration and robust code interactions with LLMs.
          </p>
        </div>
      </div>
    </section>

    <!-- Response Modelling -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>ClickSense</h2>
          <p class="subtitle">User response modelling at scale through CTR and CVR prediction</p>
          <img src="rtl.png" alt="Response Modelling Illustration"/>
        </div>
        <div class="right-column">
          <p>
            A critical part of any user interaction with a user interface—be it on an app or a website—is to understand 
            what works and what doesn't. Our response modelling engine perpetually learns from 
            billions of data points each day, tailoring content to each individual's preferences 
            and behaviors.
          </p>
          <p>
            By showing content users are most likely to click or buy, we ensure higher engagement 
            and conversion rates across the board.
          </p>
        </div>
      </div>
    </section>


    <!-- Document Understanding -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>DeepExtract</h2>
          <p class="subtitle">Document Understanding from Transcripts, PDFs, Images and Text</p>
          <img src="rtl.png" alt="Document Understanding Illustration"/>
        </div>
        <div class="right-column">
          <p>
            We built an LLM-first entity extraction engine that can understand malforformed data like
            error-laden transcripts and noisy images and convert that into stored and queryable entities.
            By harnessing LLMs as a central knowledge base, instead of a conversational agent, we achieved 
            multi-modal capabilities. Our system can process physical receipts or even audio data and 
            extract relevant entities without needing text conversion.
          </p>
          <p>
            This library is production-ready for image and text data and is currently being developed and 
            tested for voice, offering seamless document comprehension regardless of input format.
          </p>
        </div>
      </div>
    </section>

    <!-- LLM Powered Recommendations -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>SwishList</h2>
          <p class="subtitle">LLM Powered Relevance Layer for Recommendations</p>
          <img src="soon.png" alt="LLM Recommendations Illustration"/>
        </div>
        <div class="right-column">
          <p>
            Recommendations are about aligning the right content with the right users. Our library 
            uses LLMs to incrementally embed a user’s past behavior into a vector space. We embed content
            into the same space to identify the content that is most relevant to the user's behaviour.

            Using this library one can also get goal specific recommendations like cross selling, 
            up selling or attaching accessories.
          </p>
          <p>
            We have deployed this approach to great effect, delivering outstanding results for our 
            clients. By merging classic recommender system logic with modern LLM and embedding 
            techniques, we boost relevance and user satisfaction.
          </p>
        </div>
      </div>
    </section>

    <!-- AI Product Image Generation -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>Photogenic</h2>
          <p class="subtitle">AI Product Photoshoot Image Generation</p>
          <img src="rtl.png" alt="AI Product Image Generation Illustration"/>
        </div>
        <div class="right-column">
          <p>
            We built a library that places real-world products into artificially generated 
            environments, producing picture-perfect product photos. Unlike many unconstrained 
            AI-generated images that may be eye-catching but lack business utility, our approach 
            algorithmically constrains images using a variety of ControlNets for practical outcomes.
          </p>
          <p>
            Whether you need consistent branding, contextual backgrounds, or stylized imagery, 
            our system can deliver professional, on-brand visuals every time.
          </p>
        </div>
      </div>
    </section>

    <!-- Operations Research -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>OptimiCraft</h2>
          <p class="subtitle">Operations Research</p>
          <img src="soon.png" alt="Operations Research Illustration"/>
        </div>
        <div class="right-column">
          <p>
            Translating complex business and operational requirements into mathematical constraints 
            can be challenging. Our in-house translation layer software, integrated with popular 
            solvers like CVXOPT, Mosek, and Gurobi, supports both open-source and commercial-grade 
            solvers.
          </p>
          <p>
            This flexibility allows you to handle everything from small-scale linear optimizations 
            to large-scale number-crunching, enabling an operations framework that is both 
            powerful and efficient.
          </p>
        </div>
      </div>
    </section>

    <!-- Forecasting -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>Prophesize</h2>
          <p class="subtitle">Traffic Forecasting System to Predict Audience Segments</p>
          <img src="rtl.png" alt="Forecasting Illustration"/>
        </div>
        <div class="right-column">
          <p>
            Our high-performance forecasting engine predicts user access patterns up to 60 days 
            into the future, a critical component of advertising systems that enable companies 
            to book deals in advance.
          </p>
          <p>
            By combining classical statistical methods with cutting-edge deep learning models, 
            our forecasting library ensures reliability, scalability, and a competitive edge in 
            planning and resource allocation.
          </p>
        </div>
      </div>
    </section>

    <!-- LLM Finetuning -->
    <section class="boxed-section">
      <div class="section-content">
        <div class="left-column">
          <h2>DialUp</h2>
          <p class="subtitle">LLM Finetuning System to Compress Task Specific LLMs</p>
          <img src="soon.png" alt="LLM Finetuning Illustration"/>
        </div>
        <div class="right-column">
          <p>
            Large LLMs can be expensive when we only need specific tasks to be performed. Our fine-tuning 
            library built on LLM Finetuning creates smaller, task-specific LLMs that run efficiently 
            while still delivering high-quality results.
          </p>
          <p>
            This approach lets you focus on specialized tasks without the cost and complexity of a 
            massive general-purpose model, offering faster insights and better ROI.
          </p>
        </div>
      </div>
    </section>
  </main>

  <!-- FOOTER -->
  <footer>
    <p>
      &copy; 2004-25 AI in a Box, Minivet AI Consulting LLP. All rights reserved. | 
      <a href="https://aiinabox.in" target="_blank">aiinabox.in</a>
      <a href="https://minivet.ai" target="_blank">minivet.ai</a>
    </p>
  </footer>

  <!-- JavaScript for Fade-in Animation on images in the boxed sections -->
  <script>
    function fadeInImages() {
      // Only target images in the .boxed-section
      const images = document.querySelectorAll('.boxed-section img');
      images.forEach((img, index) => {
        // Add a slight delay so they fade in one after another
        setTimeout(() => {
          img.classList.add('reveal');
        }, index * 200);
      });
    }
  </script>

</body>
</html>
